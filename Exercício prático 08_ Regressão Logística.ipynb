{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício de Programação: Regressão Logística e Softmax com MNIST\n",
    "\n",
    "Neste exercício, você aplicará os conceitos de Regressão Logística para classificação binária e Regressão Softmax para classificação multiclasse. Usaremos o famoso dataset MNIST, que consiste em imagens de dígitos manuscritos.\n",
    "\n",
    "**Objetivos:**\n",
    "1. Treinar um classificador binário para identificar se um dígito é '5' ou 'não-5'.\n",
    "2. Treinar um classificador multiclasse para identificar os dígitos de 0 a 9.\n",
    "3. Avaliar a performance de ambos os modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação do Ambiente e Carregamento dos Dados\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e carregar o dataset MNIST.\n",
    "\n",
    "Também vamos pré-processar os dados: \n",
    "- Dividir em conjuntos de treino e teste.\n",
    "- Escalar os valores dos pixels para melhorar a performance do gradiente descendente.\n",
    "- Remodelar as imagens de 28x28 para vetores de 784 dimensões, que é o formato esperado por um classificador como `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato dos dados de treino: (1600, 64)\n",
      "Formato dos dados de teste: (197, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregar o dataset MNIST\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "X_train, X_test = X[:1600], X[1600:]\n",
    "y_train, y_test = y[:1600], y[1600:]\n",
    "\n",
    "# Escalar os pixels\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Remodelar as imagens para vetores 1D (28*28 = 784)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(f\"Formato dos dados de treino: {X_train_flat.shape}\")\n",
    "print(f\"Formato dos dados de teste: {X_test_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Treinando um Classificador Binário (5 ou não-5)\n",
    "\n",
    "Agora, vamos criar um classificador para uma tarefa binária: detectar se um dígito é o número 5 ou não. Para isso, precisamos ajustar nossos rótulos (`y_train` e `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo de Regressão Logística treinado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tailan/Documentos/6 Semestre/Aprendizado de Maquina/resolucao dos colabs/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar o dataset MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(int)\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar os rótulos binários: True para 5, False para outros\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# Inicializar e treinar o modelo de Regressão Logística\n",
    "log_reg = LogisticRegression(max_iter=10)\n",
    "log_reg.fit(X_train, y_train_5)\n",
    "\n",
    "print(\"✅ Modelo de Regressão Logística treinado!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Classificador Binário\n",
    "\n",
    "Com o modelo treinado, vamos avaliar sua acurácia no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia usando .score(): 0.9629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_5 = log_reg.predict(X_test)\n",
    "\n",
    "# Ou usar o método .score() diretamente\n",
    "acc_score = log_reg.score(X_test, y_test_5)\n",
    "print(f\"Acurácia usando .score(): {acc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinando um Classificador Multiclasse (Regressão Softmax)\n",
    "\n",
    "O `LogisticRegression` do Scikit-Learn automaticamente lida com a classificação multiclasse usando a estratégia \"um-contra-o-resto\" (OvR) por padrão. Para usar a Regressão Softmax (também chamada de Regressão Logística Multinomial), podemos definir o argumento `multi_class='multinomial'`.\n",
    "\n",
    "Vamos treinar um novo modelo para classificar todos os 10 dígitos (0 a 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tailan/Documentos/6 Semestre/Aprendizado de Maquina/resolucao dos colabs/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regressão Softmax treinado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tailan/Documentos/6 Semestre/Aprendizado de Maquina/resolucao dos colabs/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# SEU CÓDIGO AQUI: Treine o modelo softmax usando o conjunto de treinamento com todas as classes (X_train_flat, y_train).\n",
    "\n",
    "# Inicializar o modelo de Regressão Softmax\n",
    "# Usamos max_iter=1000 para garantir a convergência.\n",
    "\n",
    "# ----------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inicializar o modelo de Regressão Softmax\n",
    "softmax_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=10)\n",
    "\n",
    "# Treinar o modelo com todas as classes\n",
    "softmax_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo de Regressão Softmax treinado!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Classificador Multiclasse\n",
    "\n",
    "Por fim, avaliamos o modelo multiclasse no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo multiclasse: 0.8826\n"
     ]
    }
   ],
   "source": [
    "# Calcular e imprimir a acurácia no conjunto de teste\n",
    "accuracy = softmax_reg.score(X_test, y_test)\n",
    "print(f\"Acurácia do modelo multiclasse: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Parabéns! Você implementou e avaliou com sucesso dois tipos de classificadores lineares:\n",
    "1. Um classificador de Regressão Logística para uma tarefa binária.\n",
    "2. Um classificador de Regressão Softmax para uma tarefa multiclasse.\n",
    "\n",
    "Você deve notar que, embora simples, esses modelos já alcançam uma acurácia razoavelmente alta para o reconhecimento de dígitos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
